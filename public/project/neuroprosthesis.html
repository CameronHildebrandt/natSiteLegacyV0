<!DOCTYPE html>
<html>

  <head>
    <title>NeurAlbertaTech</title>
    <!-- <link rel="icon" type="image/png" href="../images/NATBrain.png"/> -->
    <link rel="icon" type="image/png" href="/images/NATBrain.svg"/>

    <!-- Website created by Cameron Hildebrandt -->

    <!-- Import JQuery -->
    <script type='text/javascript' src="https://code.jquery.com/jquery-1.11.2.js"></script>

    <!-- External CSS -->
    <link href="../style.css" rel="stylesheet" type="text/css">

    <!-- External JS -->
    <script type="text/javascript" src="../scrollBackground.js"></script>
    <script type="text/javascript" src="../burgerController.js"></script>

    <!-- Add Our Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Maven+Pro:wght@400;700;900&display=swap" rel="stylesheet">
    <meta name="viewport" content="width=device-width">
  </head>

  <body>

    <div id="burger">
      <div class="burgerPart" id="topBun"></div>
      <div class="burgerPart" id="patty"></div>
      <div class="burgerPart" id="bottomBun"></div>
    </div>

    <div class="mobileMenu">
      <a href="/index.html"><button class="mobilePageLink">Home</button></a>
      <a href="/projects.html"><button class="mobilePageLink">Projects</button></a>
      <a href="/team.html"><button class="mobilePageLink">Team</button></a>
      <a href="/events.html"><button class="mobilePageLink">Events</button></a>
      <a href="/community.html"><button class="mobilePageLink">Community</button></a>
      <a href="/contact.html"><button class="mobilePageLink">Contact</button></a>
    </div>

    <div id=headerBar>
      <a href="/index"><image id="headerImg" src="/images/nat.svg" alt="NAT Logo"></image></a>

      <a href="/contact.html"><button class="pageLink">Contact</button></a>
      <a href="/community.html"><button class="pageLink">Community</button></a>
      <a href="/events.html"><button class="pageLink">Events</button></a>
      <a href="/team.html"><button class="pageLink">Team</button></a>
      <a href="/projects.html"><button class="pageLink">Projects</button></a>
      <a href="/index.html"><button class="pageLink">Home</button></a>
    </div>

    <div style="position: relative"><div class="spinner"></div></div>
    <img id="headerBGImg" lsrc="/images/ProjectPhotos/bermuda/main.jpg"></img>
    <img id="headerBGDiv"></img>


    <div id=scrollContainer>
      <div id=divAboveMainForSnapping></div>
      <div id=divAboveMainForGradient></div>

      <div id="main">



        <!-- <h1 class="subTitle" style="margin-left: 2%;">Bermuda Hardware Project</h1> -->
        <div id="largeInfoBlock">
          <div id="largeInfoContents" style="margin-top: 1%;">



            <div id="largeInfoBlockText">
              <div class="subSubTitle" style="margin-bottom: 15px;">NAT Neuroprosthesis</div>
              <p class="paragraph">This team is developing an electroencephalogram and electromyography (EEG/EMG)-controlled prosthetic hand from scratch.</p>
            </div>

            <div id="largeInfoBlockMedia">
              <div id="largeMediaFrame">
                <img src="/images/ProjectPhotos/neuroprosthesis/mold.jpg" style="width: 80%;"></img>
              </div>
              <!-- <a href='https://github.com/neuralbertatech/openComp2020' target="_blank"><button id="smallButton">Github</button></a> -->
            </div>

          </div>
        </div>




        <div id="largeInfoBlock">
          <div id="largeInfoContents" style="margin-top: 1%; display: block;">
            <div class="subTitle" style="margin-bottom: 15px;">NAT Neuroprosthesis?</div>
            <div class="subSubSubTitle" >Objectives</div>
            <br>
            <p class="paragraph">
              Prosthetics are becoming increasingly prevalent in a world where day-to-day actions are often limited to those without disabilities. Bridging this gap, NeurAlbertaTech is currently building an electroencephalogram and electromyography (EEG/EMG)-controlled prosthetic hand from scratch.
              <br>
            </p>
            <div class="subSubSubTitle" >Rapid Development</div>
            <br>
            <p class="paragraph">
              For the mechanical side of this prototype, parts will be 3D printed to promote customizability and affordability. The 3D models will also be easy to replicate, promoting accessibility in prosthetics and rehabilitation products. In terms of functionality, the hand would offer flexibility in individual finger movements and wrist rotation. Prototyping includes:
              <br>
               • Research and development of preliminary 3D designs
              <br>
               • 3D printing parts using PLA, ABS, PETG, and TPU
              <br>
               • Testing of prototype by integrating hardware and software together
               <br>
              </p>
            <div class="subSubSubTitle" >User Interaction</div>
            <br>
            <p class="paragraph">
              Since sensory feedback from the hand is absent in most  prostheses, an artificial method to restore this sense is crucial in performing day to day tasks such as grasping objects. Using a custom embedded flex sensor made from Velostat and Ecoflex, preliminary tests have been run consisting of:
              <br>
               • 3D printing PLA/ABS molds for casting
              <br>
               • The casting process which includes a layer of Ecoflex, a Velostat sheet, then another layer of Ecoflex
              <br>
               • Curing the Ecoflex in a vacuum chamber
              <br>
              <br>
              Connecting the exposed Velostat tabs to an Arduino which routes it to a small vibration motor for sensory feedback.
              The goal of this test is to provide a Proof of Concept (PoC) for a feedback system within the prosthetic hand. With the Velostat layer acting as an electronic skin for the prosthesis, it should be sensitive to changes in pressure and other tactile sensations. Through the Velostat’s ability to change resistance based on applied pressure, differing pressures can be distinguished by Arduino as differing currents. This way, the hand would be able to relay sensory information from the Velostat to the user, restoring their both sensory and motor function.
            </p>
          </div>
        </div>

        <div class="greyBG" style="padding:2%;">

          <div id="interestedBlockContents">

          <span style="color: rgba(255,255,255,1); font-size: 35px; font-weight: 900; font-family: 'Maven Pro', sans-serif;">Neuroprotheis Project Team</span>
          <!-- <div id="smallImage" style="width: 100%; margin-top: 10px; margin-bottom: 30px; height: 100%;">
            <img src="../images/Headshots/CameronHeadshot2.jpg" style="width: 100%"></img>
          </div> -->


          <!-- <div style="color: rgba(255,255,255,1); font-size: 35px; font-weight: 900; font-family: 'Maven Pro', sans-serif;">Members</div> -->

          <div id="viewPastExecsContentScrollContainer">
            <table style="width:100%" class="pastExecsTable">
              <tr>
                <th>
                  <div id="smallImage">
                    <a href="https://www.linkedin.com/in/portia-rayner-376689172/"><img src="/images/Headshots/PortiaHeadshot.jpg" id="smallImageChild"></img></a>
                  </div>
                </th>

                <th>
                  <div id="smallImage">
                    <a href="https://www.linkedin.com/in/please-hire-me-thank-you/"><img src="/images/ProjectPhotos/neuroprosthesis/team/Annette_Lau.JPG" id="smallImageChild"></img></a>
                  </div>
                </th>

                <th>
                  <div id="smallImage">
                    <a href="https://www.linkedin.com/in/daniel-gye-4b3675184/"><img src="/images/ProjectPhotos/neuroprosthesis/team/Daniel.jpg" id="smallImageChild"></img></a>
                  </div>
                </th>

                <th>
                  <div id="smallImage">
                    <a href="https://www.linkedin.com/in/haseeb-mohammad-806577186/"><img src="/images/ProjectPhotos/neuroprosthesis/team/Headshot_Haseeb.jpg" id="smallImageChild"></img></a>
                  </div>
                </th>

                <th>
                  <div id="smallImage">
                    <a href="mailto:palamar@ualberta.ca"><img src="/images/ProjectPhotos/neuroprosthesis/team/Randy.jpg" id="smallImageChild"></img></a>
                  </div>
                </th>


              </tr>



              <tr style="font-family: 'Maven Pro'; color: rgba(255,255,255,1);">
                <th>Portia Rayner</th>
                <th>Annette Lau</th>
                <th>Daniel Gye</th>
                <th>Haseeb Mohammad</th>
                <th>Randy Palamar</th>
              </tr>

              <tr style="font-family: 'Maven Pro'; color: rgba(255,255,255,1);">
                <td><b>Team Lead - BSc, Mechanical Engineering</b></td>
                <td><b>3D Modelling, Additive Fabrication - BSc, Mechanical Engineering</b></td>
                <td><b>Mold Fabrication, Clinical Liaison - BSc, Mechanical Engineering</b></td>
                <td><b>Materials Researcher - BSc, Electrical Engineering</b></td>
                <td><b>PCB Design, Embedded Systems - BSc, Electrical Engineering</b></td>
              </tr>

              <!-- <tr style="font-family: 'Maven Pro'; color: rgba(255,255,255,1); vertical-align: top;">
                <td>Responsible for coordinating communication and collaboration between software and hardware developers as well as between the sub-teams working on each of the three modalities that make up Bermuda. Eden also sets project goals and oversees the progression towards these milestones, beyond this he works hands-on where he is needed in order to keep the project moving forward.  </td>
                <td>Responsible for conceptualizing and developing the body tracking system for Bermuda. Landon is using lightweight deep learning models to provide real-time pose estimation. He is building the system centered around a Raspberry Pi to keep costs down along with a stereo camera module to allow for identification of 3D locations of parts.  </td>
                <td>Responsible for aiding all teams in hardware development, with an emphasis on the EEG team. James is responsible for developing the initial in-house EEG prototype that allows for future scalability, through which the project is poised to have a significant impact in the research community, and beyond.</td>
                <td>Responsible for designing and programming the user interface for Bermuda. Madeleine is working on integrating the data streams from the project's three elements into a single interface, which will allow easy access to the information and simplify future applications of the system.</td>
                <td>Responsible for SPI communication between the Raspberry Pi and the ADS1299 analog to digital converter used in the collection of EEG data. One of Bermuda’s main design constraints will be tracking free moving bodies therefore Sebastian works to eliminate wires that could impede movement through the use of a QN9080SIP, an Ultra-low-power Bluetooth 5 SIP, to transfer EEG data to an on-board laptop BLE.</td>
              </tr> -->

            </table>
          </div>

        </div>

      </div>
    </div>


    <script type="text/javascript">
      // To allow Burger to Work
      menuToggle();
    </script>

    <script type="text/javascript">

      $(document).ready(function(){
        $('#viewPastExecsButton').click(function(){
          if($('#viewPastExecsButton').text() === "View 2019 Project Team") {

            // Button
            $('#viewPastExecsButton').text("Back");
            $('#viewPastExecsButton').css('background-color', 'rgba(0, 0, 0, 1)');

            // Content
            $('#viewPastExecsContent').css("height","500px"); // so we never hit it
            $('#viewPastExecsContent').css("margin-top","-50px");
            $('#viewPastExecsContent').css("opacity","100");
            $('#viewPastExecsContent').css("padding-bottom","2%");
            $('#viewPastExecsContent').css("padding-top","70px");
            // $('#viewPastExecsContent').css("transform","scaleY(1)");

            // Container
            $('#viewPastExecsContentContainer').css("display","block");
          } else {
            // Button
            $('#viewPastExecsButton').text("View 2019 Project Team");
            $('#viewPastExecsButton').css("background-color", "rgba(0, 0, 0, 0.8)");

            // Content
            $('#viewPastExecsContent').css("height","0px");
            $('#viewPastExecsContent').css("margin-top","0px");
            $('#viewPastExecsContent').css("opacity","0");
            $('#viewPastExecsContent').css("padding-bottom","0px");
            $('#viewPastExecsContent').css("padding-top","0px");
            // $('#viewPastExecsContent').css("transform","scaleY(0)");

            // Container
            $('#viewPastExecsContentContainer').css("display","none");
          }
        });
      });

    </script>


    <!-- Show data processing -->
    <script>
      $(document).ready(function(){
        var currStage = 0;
        var dataParagraph = document.getElementById("dataParagraph");
        var stageParagraphs = [
          'This is what the raw data from the OpenBCI looks like. Each graph represents a one second window of one of the 16 channels, hence why there is 16 graphs for the single sample. You may notice that this data is actually quite spiky and sporradic. While it is true that some of that spiky data represents high frequency (gamma) brain waves, the grand majority of it is actually noise and imperfect representations of our data. A rather straightforward thing that we can do to muffle the noise and "hone in" on the brain signal is just smooth out the curve. We can apply something called a Savitzky-Golay (savgol) filter, which will do precicely that. You can read more about how exactly a savgol filter works <a href="https://en.wikipedia.org/wiki/Savitzky-Golay_filter"  id="uncoloredLink" target="_blank">here</a>. <br><br><b>Click on the data to apply the savgol filter.</b>',

          "Now that we have smoothed out the data, it is much easier to see the underlying waves, which means that the Fourier transform will likely be able to better represent what is actually going on with the data. Let's pass each of the individual channels through a Fourier transform. <br><br><b>Click on the data to pass the channels through a Fourier transform.</b>",

          "Fantastic! Though it may not look like it, you are looking at the exact same data. The Fourier transform doesn't actually change the data at all, it simply changes the way we represent it. Here the data is represented in the frequency domain instead of the time domain, so the different peaks of these graphs show relative strengths of each frequency in the overall signal as opposed to showing the overal signal itself. It may not be immediately obvious what's going on here, but this is actually really powerful. This transform allows us to use our neuroscience knowledge to further interpret this data. <br><br><b>Click on the data to further analyze the data.</b>",

          "This is the exact same thing, but now we have fancy lines drawn on it! These lines are placed to break up the data into the regions of 0.5-4 Hz, 4-7.5 Hz, 7.5-12 Hz, 12-30 Hz, and 30-100 Hz. These regions correspond to the delta, theta, alpha, beta, and gamma power bands respectively. What we want to do now is calculate a numerical representation of the relative strength of each of these bins. To do that, we simply average every point in each of these bins. <br><br><b>Click on the data to find the binned values.</b>",

          "Now we have an incredibly simple representation of the entire sample that contains just 5 numbers, the relative strength of each of the power bins, for each of the 16 channels. Having these bins of data is incredibly powerful, as we can interpret the data over time to see how it changes, and we can even compare how these bins change over time compared to each other to determine rather complex occurances in the brain, such as mood, attention level, and calmness. For our classifier application, however, we sort of skim over this nuance. We don't exactly know how your calmness, attention, etc. correlate to our directional labels, so we are just going to directly feed this data into the LDA classifier and leave it to discover that for us. Let's compress this data a little more. <br><br><b>Click on the data to compress this data further.</b>",

          "Here we have simply averaged the strength of all of the bins to discover 5 numbers that represent the entire sample. We have now preprocessed one sample for the Fourier model! The program follows this process for every sample that we record to build a dataset of these bits of data above that will all go towards training our Fourier LDA Model.<br><br><b>Click on the data to reset this exercise.</b>"];


        // Preload images to make activity super snappy
        var i;
        for (i = 0; i <= 5; i++) {
          var img=new Image();
          img.src="../images/ProjectPhotos/dataExample/" + i + '.jpg';
        }

        $('.dataExample').click(function(){
          if(currStage < 5){
            currStage = currStage + 1
          }
          else {
            currStage = 0
          }

          $('.dataExample').attr('src', '../images/ProjectPhotos/dataExample/' + currStage + '.jpg');
          dataParagraph.innerHTML = stageParagraphs[currStage];
        });
      })
    </script>

    <!-- Dynamically Load Header -->
    <script type="text/javascript" src="/dynamicLoad.js"></script>

  </body>

</html>
